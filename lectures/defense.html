<!DOCTYPE html>
<html>

<head>
  <title>Sources of variability</title>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
  <link rel="stylesheet" href="fonts/quadon/quadon.css">
  <link rel="stylesheet" href="fonts/gentona/gentona.css">
  <link rel="stylesheet" href="slides_style_i.css">
  <script type="text/javascript" src="assets/plotly/plotly-latest.min.js"></script>
</head>

<body>
  <textarea id="source">



<!-- TODO add slide numbers & maybe slide name -->

### Sources of variability in high-dimensional datasets

![:scale 40%](images/neurodata_blue.png)

| Eric W. Bridgeford | {Biostatistics, BME, CIS} |
| --- | --- |
| [ericwb95@gmail.com](mailto:ericwb95 at gmail dot com)  | [ericwb.me](https://ericwb.me) |

---
name:talk

### Outline

- [Motivation](#defn)
- [Replicability of High-Dimensional Measurements](#discr)
- [Variability in High-Dimensional Measurements](#causal)
- [Discussion](#disc)

### [Additional Content](#extra)

---
name:defn

### Outline

- Motivation
- [Replicability of High-Dimensional Measurements](#discr)
- [Variability in High-Dimensional Measurements](#causal)
- [Discussion](#disc)

### [Additional Content](#extra)

---

### Typical approach to inference

<p align="center">
  ![:scale 60%](images/defense/typical.png)
</p>
- goal: establish relationship between exposure of interest and data samples, conditional on other covariates
    - conclusion is externally valid: our analysis "generalizes"
- domain expertise: context for unmeasured variables

---

### Measurements are usually manipulated prior to analysis

<p align="center">
  ![:scale 100%](images/defense/typical2.png)
</p>
- the measurement that we obtain is rarely the measurement of interest
  - .ye[derivative]: information that is a function of a raw measurement that is used to learn about the data

---

#### Similar measurements can be collected using many different techniques

![:scale 100%](images/defense/typical3.png)

- small differences in acquisition protocols (device used, settings, technician preparation, etc.) can impart biases to measurements

---

### Reality of inference

![:scale 100%](images/defense/reality.png)

- .ye[Accidental deviations]: sources of variability not of scientific interest
- .ye[Systematic deviations]: variability of interest
- fundamental question of data science: identify systematic deviations in the presence of accidental deviations

---

### Connectome data

- connectome: brain graph, where the edges indicates the level of functional similarity or structural connectivity between areas of the brain
<p align="center">
  ![:scale 50%](images/defense/fmri_conn.png)
</p>
  - very high-dimensional
  - properties about graph $\Rightarrow$ insights about brain function
- expense $\Rightarrow$ collect data and pool

---

### What data will we be using?

- CoRR mega-study
- $N>1,700$ individuals imaged across $26$ different "batches"
  - anatomical MRI and fMRI scans for each
  - Individuals are measured at least twice

---

name:discr

### Outline

- [Motivation](#defn)
- Replicability of High-Dimensional Measurements
  - [Background](#discr-mot)
  - [Results](#discr-results)
  - [Discussion](#discr-disc)
- [Variability in High-Dimensional Measurements](#causal)
- [Discussion](#disc)

### [Additional Content](#extra)

---

name:discr-mot

### Outline

- [Motivation](#defn)
- Replicability of High-Dimensional Measurements
  - Background
  - [Results](#discr-results)
  - [Discussion](#discr-disc)
- [Variability in High-Dimensional Measurements](#causal)
- [Discussion](#disc)

### [Additional Content](#extra)

---

### What is Reproducibility?

- .ye[Reproducibility]: ability to replicate, or reproduce, a conclusion
- serves as a "first-pass" check for scientific utility
- currently in a "reproducibility crisis"

---

### How do we address the Reproducibility Crisis?

- fix post hoc analyses (e.g., $p$-values)?
- fix measurements (e.g., measurement reproducibility)?

Proposal: design experiments to maximize .ye[inter-item discriminability], rather than simply checking reproducibility after conducting the experiment

---

### What do we want of our data?

If we measure a sample multiple times, then each measurement of that sample is closer to all the other measurements of that sample, as compared to  any of the measurements of other samples.

![:scale 100%](images/discr/perfect_discrim.png)

Perfect discriminability

---
### What do we want of our data?

Imperfect discriminability

![:scale 100%](images/discr/imperfect_discr.png)

---
### What do we want of our statistic?

Discriminability is the probability of a measurement from the same item being closer than a measurement from a different item.

![:scale 100%](images/discr/imperfect_discr.png)

---
### Discriminability Statistic: Step 1

- Compute $N \times N$ pairwise distance matrix between all measurements
<!-- - measurements are indexed first by individual identifier, and second by "measurement session" -->

![:scale 55%](images/discr/imperfect_discr.png)
![:scale 42%](images/discr/dummy_sim_dmtx.png)

<!-- <img src="images/discr/dummy_sim_dmtx.png"/> -->
---
### Discriminability Statistic: Step 2

- For each measurement, identify which measurements are from the same individual (<font color="green">green boxes</font>)
- let $\color{green}g$ be the total number of <font color="green">green boxes = 20</font>

<img width="500px" src="images/discr/dummy_sim_dmtx_match.png"/>
---
### Discriminability Statistic: Step 3
- For each measurement, identify measurements from other individuals that are more similar than the measurement from the same individual (<font color="orange">orange boxes</font>)
- let $\color{orange}f$ be the total number of <font color="orange">orange boxes = 84</font>

<img src="images/discr/dummy_sim_dmtx_closer.png"/>
---
### Discriminability Statistic
- Discr = $1 - \frac{\color{orange}f}{N(N-1) - \color{green}g} = 1 - \frac{\color{orange}{84}}{20\cdot 19 - \color{green}{20}} \approx .77$

<img src="images/discr/dummy_sim_repr.png"/>

High discriminability: same-item measurements are more similar than across-item measurements
---

### Discriminability is Construct Valid
<img src="images/discr/dummy_sims.png" style="height: 350px"/>

<!-- - under the given construct (what the simulation is supposed to show), discriminability provides a sensible statistic -->
  <!-- - other approaches do not -->
---

name:discr-results

### Outline

- [Motivation](#defn)
- Replicability of High-Dimensional Measurements
  - [Background](#discr-mot)
  - Results
  - [Discussion](#discr-disc)
- [Variability in High-Dimensional Measurements](#causal)
- [Discussion](#disc)

### [Additional Content](#extra)

---
### Analysis Procedure

Process each  measurement using $192$ different pipelines
  1. Brain alignment (ANTs/FSL)
  2. Frequency filtering (Y/N)
  3. Scrubbing (Y/N)
  4. Global Signal Regression (Y/N)
  5. Parcellation (4 options)
  6. Rescaling connectomes (Raw, Log, Pass-to-Rank)

$192 = 2 \times 2 \times 2 \times 2 \times 4 \times 3$ 

All options represent strategies experts consider useful

---
### Pipeline impacts discriminability
<center><img src="images/discr/fmri_cmp.png" style="height: 420px"/></center>

<!-- - Consequence: choosing how to pre-process your data matters -->

---
### Marginally most discriminabile options tend to be best global options
<center><img src="images/discr/individual_methods.png" style="height: 200px"/></center>
- Each point is the pairwise difference holding other options fixed (e.g., FNNGCP - ANNGCP)
- Best pipeline marginally (FNNGCP) is second best pipeline overall, and not much worse (2-sample test, p=.14) than the best pipeline FNNNCP
- We may not need to always try every pre-processing strategy every time

---
### Selection via Discriminability improves inference
For each pre-processing strategy, for each dataset, compute:
1. Within-dataset Discr.
2. Demographic effects (sex and age) within the dataset via Distance Correlation (DCorr)
3. Within a single dataset, regress demographic effect on Discr.

Question: does a higher discriminability tend to yield larger effects for known biological signals?
---
### Selection via Discriminability improves inference
<img src="images/discr/dependence.png" style="height: 400px"/>
<!-- - Consequence: maximizing discriminability in general improves downstream inference -->

---

### Outline

- [Motivation](#defn)
- Replicability of High-Dimensional Measurements
  - [Background](#discr-mot)
  - [Results](#discr-results)
  - Contributions
- [Variability in High-Dimensional Measurements](#causal)
- [Discussion](#disc)

### [Additional Content](#extra)

---

### Contributions

1. Discriminability quantifies the contributions of systematic and accidental deviations
3. Provide theoretical motivation for discriminability in connection with predictive accuracy (not discussed)
2. Formalize tests for assessing and comparing discriminabilities within and between collection strategies
4. Illustrate the value of discriminability for neuroscience and  genomics (not discussed) data
5. Code implementations in [python](https://github.com/neurodata/hyppo) and [R](https://github.com/neurodata/r-mgc)

---

### Contributions

How do we address the impact of too many processing strategies, and arbitrary subsequent tasks?

![:scale 100%](images/defense/reality.png)


---

### Contributions

How do we address the impact of too many processing strategies, and arbitrary subsequent tasks?

- .ye[Maximize desirable characteristics (e.g., discriminability) over massive mega-studies, and adopt strategies which have passed this test]

<center>![:scale 60%](images/defense/causal_dag.png)</center>

---

name:causal

### Outline

- [Motivation](#defn)
- [Replicability of High-Dimensional Measurements](#discr)
- Variability in High-Dimensional Measurements
  - [Background](#causal-mot)
  - [Theory](#causal-theory)
  - [Results](#causal-results)
  - [Discussion](#causal-disc)
- [Discussion](#disc)

### [Additional Content](#extra)

---
name: causal-mot
### Outline

- [Motivation](#defn)
- [Replicability of High-Dimensional Measurements](#discr)
- Variability in High-Dimensional Measurements
  - Background
  - [Theory](#causal-theory)
  - [Results](#causal-results)
  - [Discussion](#causal-disc)
- [Discussion](#disc)

### [Additional Content](#extra)

---

### The problem of batch effects

- .ye[batch effect]: the impact of the data collection procedure (measurement device, measurement protocol, season, etc.) on the data collected
- .ye[demographic effect]: impact on the data of scientifically "interesting" characteristics of the object under study
- When datasets are demographically diverse (high confounding) and measurements are large (high number of features), difficult to <tagname style="color:red">mitigate batch effects</tagname> while <tagname style="color:green;">preserving demographic effects</tagname>

---

### DAG for a neuroimaging study

<center>![:scale 100%](images/causal/CoRR_DAG.png)</center>

---

### Existing work (correction)

- ComBat (Johnson 2007)
  - fit a linear model, where individual "batches" are a linear transformation of one another
  - optional: "adjust" with terms for covariates (e.g., age, sex)

--
- Surrogate Variable Analysis (SVA, Leek 2007/2014)
  - use latent variable models to capture sources of batch heterogeneity

--
- NeuroHarmonize (Pomponio 2020)
  - estimate covariate relationships with Generalized Additive Models (GAMs)

---

### How do we propose to address batch effects?

- skip to latent variable modelling (e.g., SVA)?
- focus on estimation with linear/non-linear models (e.g., ComBat, NeuroHarmonize)?

Proposal: leverage techniques from .ye[causal inference] to yield strategies which are both theoretically and empirically sensible for batch effect analyses
- develop suitable language and estimands which allow us to be .ye[precise] when referring to batch effects

---

name:causal-theory

### Outline

- [Motivation](#defn)
- [Replicability of High-Dimensional Measurements](#discr)
- Variability in High-Dimensional Measurements
  - [Background](#causal-mot)
  - Theory
  - [Results](#causal-results)
  - [Discussion](#causal-disc)
- [Discussion](#disc)

### [Additional Content](#extra)

---

### General notation

| Symbol | Interpretation |
| --- | --- |
| $U$ | random variable |
| $u$ | realization of random variable $U$ |
| $F\_{U \vert v}$ | distribution of $U$ conditional on $V = v$ |
| $f\_{U \vert v}(u)$ | density of $u$ conditional on $V = v$ |
| $P\_{U \vert v}(u)$ | probability of $U = u$ conditional on $V = v$ |

---

### Specific notation

| Symbol | Interpretation |
| --- | --- |
| $Y_i$ | random variable representing an outcome |
| $T_i$ | random nominal ($1$ of $K$) exposure |
| $X_i$ | random variable representing measured covariates |
| $Z_i$ | random variable representing unmeasured covariates |
| $Y_i(t)$ | potential outcome under exposure $t$ |

---

### Causal discrepancy

Let $ F\_{Y\_i\(t\)| x, z}$ denote the potential outcome distribution, conditional on the measured .ye[and] unmeasured covariates
  - distribution we would expect in exposure $t$ for an individual $i$ with covariates $(x, z)$
$$\forall t \in [K]:\;\;\;\;f\_{Y\_i(t)}(y) = \int\_{\mathcal X, \mathcal Z} f\_{Y\_i\(t\)| x, z}(y) f(x,z) d(x,z)$$

for two exposures $k$ and $l$, there is a .ye[causal discrepancy] if:

$$F\_{Y\_i(k)} \neq F\_{Y\_i(l)}$$

--
- idea: potential outcomes (e.g., connectomes) for an individual differ in exposures (e.g., batches) $k$ and $l$
- "batch effect"

---

### Observational studies and causality

- .ye[observational study]: exposure is not controlled directly by the experimenters
  - $Y_i$ and $Y_i(t)$ do not, in general, have similar conditional/unconditional distributions

--
- problem: sensible definition of a batch effect relies on potential outcomes $Y_i(t)$

--
- what other estimands "might" people discuss?

---

### Testing for batch effects

##### Conditional setting
- observe $\left(y_i, x_i, t_i\right)$ for all $i \in [n]$
- Determine $F\_{Y\_i | k, x} \neq F\_{Y\_i | l, x}$ for batches $k, l$
- causal if ignorability, covariate overlap hold
  - if covariates "different enough" across batches, not causal

---

### Detecting batch effects

- detection tends to be an easier problem than estimation
- Universally consistent tests readily exist for natural tests for non-causal effects in general settings (bounded variance)

.ye[implication]: don't need to limit the scope of distributions under consideration, nor the types of "differences" that can exist between exposures

--
- problem: existing approaches tend to perform poorly (finite sample) when positivity assumption is violated

---

### Overlap and batch effects (conditional)

<center>![:scale 60%](images/causal/ass_fail.png)</center>

- Overlap is a pre-hoc criterion: $P\_{T\_i | x}(t) > 0$ for all $x, t$
- "Approximate" overlap? Propensity trimming

---

### Propensity Trimming

- use generalized propensity score to "trim" individuals with extremely low (or high) propensities for particular exposures
  - generalizes well to $K \geq 2$ exposures

<center>![:scale 100%](images/causal/vm.png)</center>

- Causal $\texttt{cDCorr}$: prepend VM to $\texttt{cDCorr}$

---

### Causal effect removal

A function $g$ removes the causal discrepancy between exposures $k$ and $l$ if:

$$F\_{Y\_i(k)} \neq F\_{Y\_i(l)}$$

and:

$$F\_{g(Y\_i(k), k)} = F\_{g(Y\_i(l), l)}$$

--

- idea: $g$ is a (usually unknown) function which "corrects" the disparity between potential outcomes

--
- "batch effect correction": estimating $g$ via $\hat g$

---

### Removing batch effects

##### Crossover setting

- estimate $\hat g$ using $\left(y_i(t), x_i(t)\right)$ for all ${\color{yellow}{t \in [K]}}, i \in [n]$
- if states are changing, use conditional technique, else, associational

##### Associational setting

- estimate $\hat g$ using $\left(y_i, t_i\right)$ for all $i \in [n]$

##### Conditional setting

---

### Conditional $\texttt{ComBat}$

- estimate $\hat g$ using $\left(y_i, t_i, x_i\right)$ for all $i \in [n]$

$\texttt{cComBat}$: model "batch" as a linear transform of an "underlying" signal

$$y\_i = \alpha\_{t\_i} \left(f(x\_i) + \beta\_{t\_i}\right)$$
where $f$ is known

--
- estimate $\alpha\_{t\_i}$ and $\beta\_{t\_i}$ via regression approaches
- How critical is "knowing" $f$?

---

### Simulation

Let $\mathbb E[Y\_i(t) | x] = \beta_x f(x) + \beta_0\mathbb I(t = 2)$ be the "expected signal" for a covariate level $x$ in batch $t$

<center>![:scale 60%](images/causal/sim_simple.png)</center>

---

### Simulation

Sample $(t\_i, x\_i, \epsilon\_i)$ and let $y\_i = \mathbb E[Y(t\_i) | x\_i] + \epsilon_i$ for $n=200$ points

<center>![:scale 60%](images/causal/sim_simple2.png)</center>


---

### Simulation

Fit linear model, obtain estimate of $\beta_0$

<center>![:scale 60%](images/causal/sim_simple4.png)</center>

---

### Simulation

Let $\hat g(y, t) = y - \hat \beta_0 \mathbb I(t = 2)$
- Success: $\hat g\left(\mathbb E[Y\_i(2) | x\_i], 2\right) \approx \hat g\left(\mathbb E[Y\_i(1) | x\_i], 1\right)$

<center>![:scale 60%](images/causal/sim_simple5.png)</center>

---

### When we "guess" right, balance doesn't matter

<center>![:scale 90%](images/causal/correct_spec.png)</center>

- "Extrapolation" works just fine

---

### When we "guess" wrong, disaster

<center>![:scale 90%](images/causal/incorrect_spec.png)</center>

- $\texttt{ComBat}$ will (willingly and ablely) give us arbitrarily wrong answers
- "Extrapolation" works very not fine: batch effects are worse!

---

### When we "guess" wrong, disaster

- "Extrapolation" requires extreme confidence in our model
- when the number of outcome dimensions are high, how can we possibly expect to "guess" appropriate $f$ (for every dimension)?

--

##### (Possible) solutions
- nonparametric estimation of $f$ ($\texttt{NeuroHarm}$)
  - number of samples can be low; unclear how robust techniques (e.g., GAMs) are to HDLSS (high dimensionality; low sample size) problem

--
- Matching?

---

### Matching

- .ye[Goal]: equate the empirical propensity distributions between the two batches
- .ye[Implication]: improves robustness of estimates to model misspecification (Warnbaum 2012, VDV 1998)

<center>![:scale 90%](images/causal/matching.png)</center>

---

### When we "guess" wrong, stable

<center>![:scale 90%](images/causal/incorrect_spec_causal.png)</center>

- prepending "matching" yields stable estimates of batch effects
  - limited overlap: no information to do .ye[anything]

---

name:causal-results

### Outline

- [Motivation](#defn)
- [Replicability of High-Dimensional Measurements](#discr)
- Variability in High-Dimensional Measurements
  - [Background](#causal-mot)
  - [Theory](#causal-theory)
  - Results
  - [Discussion](#causal-disc)
- [Discussion](#disc)

### [Additional Content](#extra)

---

### CoRR Demographics


<center>![:scale 100%](images/causal/demographic.png)</center>

---

### Associational/conditional effects can almost always be estimated 

<center>![:scale 70%](images/causal/ass_eff.png)</center>

---

### Effects which respect confounding biases cannot

<center>![:scale 70%](images/causal/caus_eff.png)</center>

---

### Procedure for real data analysis

.ye[Motivation]: does the manner in which we include/exclude samples for batch effect "correction" and subsequent inference matter?
- If confounding is irrelevant, smaller samples = similar inference, but (in general) higher $p$-values
  - If adjustment functions are reasonable "within covariate overlap", should get similar inference with approximate propensity trimming and fully matched

<center>![:scale 60%](images/defense/eff_exp.png)</center>

---

### Edge-wise analysis

- Effect of sex on connectivity (per edge), conditional on age

<center>![:scale 100%](images/causal/effect_size.png)</center>

- (approximate) propensity trimming and fully matching yield widely different inference (much smaller $p$-values with fully matching)

---

### Different assumptions produce radically different inference

<center>![:scale 100%](images/causal/edges.png)</center>

- compare strategies using full data to strategies using matching: almost orthogonal inference
- upstream assumptions for batch effect correction play enormous role downstream
  - is batch effect correction adding artifacts?
  - are we missing crucial variables somewhere along the way?
---

name:causal-disc

### Outline

- [Motivation](#defn)
- [Replicability of High-Dimensional Measurements](#discr)
- Variability in High-Dimensional Measurements
  - [Background](#causal-mot)
  - [Theory](#causal-theory)
  - [Results](#causal-results)
  - Discussion
- [Discussion](#disc)

### [Additional Content](#extra)

---

### Accomplishments (detection)

- developed new causal language and machinery for detection of causal effects in high-dimensional regimes
- demonstrated valid and powerful performance, unlike existing approaches (which often were neither, not discussed)

##### Implications

- causal structure learning?
- causal discovery?

---

### Accomplishments (estimation)

- revised language for batch effects to be more precise and specific
  - provides theoretical foundation for past investigations of batch effects (e.g., Fortin 2018)
- simulations reveal substantial limitations of $\texttt{ComBat}$
  - uncover the benefits of causal perspective
- discussion of paper focuses on implications of these results with internal and external validity (not discussed)
  - .ye[internal validity]: "unbiased estimand" (causal techniques prioritize this)
  - .ye[external validity]: achieve results which apply widely (non-causal techniques might achieve this, if causality doesn't matter)
- internal validity is a pre-req for external validity, so unclear the implications of non-causal protocols

---

### Acknowledgements

<div class="small-container">
  <img src="faces/jovo.png"/>
  <div class="centered">Josh Vogelstein</div>
</div>
<div class="small-container">
  <img src="faces/bcaffo.jpg"/>
  <div class="centered">Brian Caffo</div>
</div>
<div class="small-container">
  <img src="faces/carlo.jpeg"/>
  <div class="centered">Carlo Colantuoni</div>
</div>
<div class="small-container">
  <img src="faces/powell.jpg"/>
  <div class="centered">Mike Powell</div>
</div>
<div class="small-container">
  <img src="faces/shangsi.jpg"/>
  <div class="centered">Shangsi Wang</div>
</div>
<div class="small-container">
  <img src="faces/zhi.jpeg"/>
  <div class="centered">Zhi Yang</div>
</div>
<div class="small-container">
  <img src="faces/zeyi.jpeg"/>
  <div class="centered">Zeyi Wang</div>
</div>
<div class="small-container">
  <img src="faces/ting.jpeg"/>
  <div class="centered">Ting Xu</div>
</div>
<div class="small-container">
  <img src="faces/cc.jpg"/>
  <div class="centered">Cameron Craddock</div>
</div>
<div class="small-container">
  <img src="faces/jayanta.jpg"/>
  <div class="centered">Jayanta Dey</div>
</div>
<div class="small-container">
  <img src="faces/gkiar.jpg"/>
  <div class="centered">Greg Kiar</div>
</div>
<div class="small-container">
  <img src="faces/wgr.jpg"/>
  <div class="centered">William Gray-Roncal</div>
</div>
<div class="small-container">
  <img src="faces/cdouville.jpeg"/>
  <div class="centered">Christopher Douville</div>
</div>
<div class="small-container">
  <img src="faces/snoble.jpeg"/>
  <div class="centered">Stephanie Noble</div>
</div>
<div class="small-container">
  <img src="faces/cep.png"/>
  <div class="centered">Carey Priebe</div>
</div>
<div class="small-container">
  <img src="faces/mm.jpg"/>
  <div class="centered">Michael Milham</div>
</div>
<div class="small-container">
  <img src="faces/xinian.jpg"/>
  <div class="centered">Xinian Zuo</div>
</div>
<div class="small-container">
  <img src="faces/jaewon.jpg"/>
  <div class="centered">J1 Chung</div>
</div>
<div class="small-container">
  <img src="faces/sambit.jpg"/>
  <div class="centered">Sambit Panda</div>
</div>
<div class="small-container">
  <img src="faces/ross.jpg"/>
  <div class="centered">Ross Lawrence</div>
</div>
<div class="small-container">
  <img src="faces/bgilbert.jpeg"/>
  <div class="centered">Brian Gilbert</div>
</div>
<div class="small-container">
  <img src="faces/cshen.jpg"/>
  <div class="centered">Cencheng Shen</div>
</div>
<div class="small-container">
  <img src="faces/cboy.png"/>
  <div class="centered">Cramér</div>
</div>

<img src="images/funding/nsf_fpo.png" STYLE="HEIGHT:95px;"/>
<img src="images/funding/nih_fpo.png" STYLE="HEIGHT:95px;"/>

- [Discriminability paper 1](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1009279) and [Discriminability paper 2](https://arxiv.org/pdf/2005.11911.pdf)
- [Batch effects paper](https://www.biorxiv.org/content/10.1101/2021.09.03.458920v3)

---

name:extra

### [Outline](#talk)

### Additional Content

- [Discriminability](#discr-extra)
- [Causal Discrepency Testing](#causal-extra)

---

name:discr-extra

### [Outline](#talk)

### Additional Content

- Discriminability
  - [Theory](#discr-theory)
  - [Other Reproducibility Statistics](#discr-other)
  - [Limitations](#discr-limitations)
  - [Extension: Discriminability Decomposition](#discr-extension)  
- [Causal Discrepency Testing](#causal-extra)

---

name:discr-theory

### [Outline](#talk)

### Additional Content

- Discriminability
  - Theory
  - [Other Reproducibility Statistics](#discr-other)
  - [Limitations](#discr-limitations)
  - [Extension: Discriminability Decomposition](#discr-extension)  
- [Causal Discrepency Testing](#causal-extra)

---

###  Population Discriminability
- population discriminability $D$ is a .ye[property of the distribution] of measurements
<!-- - A sequence of items $x_i^k$ from individuals $i=1,..., N$ measured at time $k=1,..., s$ --> 
$D = \mathbb P(\delta(x_i^k, x_i^{k'}) < \delta(x_i^k, x_j^{k''}))$
- Probability of within-individual measurements being more similar than between-individual measurements

---
### Discriminability: unbiased and consistent
- Sample Discr. $= $fraction of times $\delta(x_i^k, x_i^{k'}) < \delta(x_i^k, x_j^{k''})$
- $i, j = 1, ..., n$ and $i \neq j$ for $n$ individuals
- $k, k', k'' = 1, ..., s$ and $k \neq k'$ for $s$ sessions
  <!-- - Probability that distances from measurements of the same individual are smaller than distances from measurements of different individuals -->
- Sample Discr. is an .ye[unbiased estimator] of $D$
- Sample Discr. converges to $D$ (.ye[asymptotically consistent] in $n$)

---
### Connecting Discriminability to Downstream Inference
<!-- - Fundamental question: does discriminability .ye[matter] for inference? -->

<!-- ##### Assumptions -->
<!-- Data follows Gaussian mixture model plus additive Gaussian noise -->

#### Assumption: Multivariate Additive Noise Setting

- $y_i \sim Bern(\pi)\;i.i.d.$,
- $\theta_i \sim \mathcal N(\mu(y_i), \Sigma_t)\;ind.$,
- (the individual means have a center which depends on the class)
--

- $\epsilon_{i}^k \sim \mathcal N(c, \Sigma_e)\;i.i.d.$ and $ind.$ of $\theta_i$,
- $x_{i}^k = \theta_i + \epsilon_i^k$.
- (the measurements $x_i^k$ are normally dispersed about the individual means)

---
### Connecting Discriminability to Downstream Inference
Suppose $(x_i^k, y_i)$ follow the Multivar. Additive Noise Setting, where $i=1, ..., n$ and $k=1,...,s$.
#### Theorem 1
There exists an increasing function of $D$, $f(D)$, which provides a lower bound on the predictive accuracy of a subsequent classification task
- $f(D) \leq A$, where $A$ is the Bayes Accuracy of the classification task

##### Consequence
- $D \uparrow \Rightarrow f(D) \uparrow$

---

#### Corollary 2
A strategy with a higher $D$ provably provides a higher bound on predictive accuracy than a strategy with a lower $D$

##### Consequence

Suppose $D_1 < D_2$, then since $f$ is increasing, $f(D_1) < f(D_2)$

##### Implication

We should use strategies with higher discriminability, as the worst-case for subsequent inference is better than a generic strategy with a lower discriminability

---

### Simulation Setup
<!-- - Construct $3$ simple simulations where the data are describable in Gaussian (or non-Gaussian) framework -->
<!-- - level of "noise" in the simulation is varied -->
  <!-- <center><img src="images/discr/sims_sim.png" style="height: 450px"/></center> -->


![:scale 70%](images/discr/sims_sim.png)

---
### Discriminability and  Accuracy

![:scale 70%](images/discr/sims_acc.png)

<!-- <center><img src="images/discr/sims_acc.png" style="height: 450px"/></center> -->

Discr. decreases proportionally with accuracy


---
### Are data discriminable?
<!-- - Fundamental question: are the data discriminable at all? -->

![:scale 70%](images/discr/sims_os.png)

---

### Is one dataset more discriminable than another?

![:scale 70%](images/discr/sims_ts.png)

---

name:discr-other

### [Outline](#talk)

### Additional Content

- Discriminability
  - [Theory](#discr-theory)
  - Other Reproducibility Statistics
  - [Limitations](#discr-limitations)
  - [Extension: Discriminability Decomposition](#discr-extension)  
- [Causal Discrepency Testing](#causal-extra)

---

#### Intraclass Correlation Coefficient (ICC)

- can be thought of as looking at the "relative size" of the within-group vs total variance
- $y_i^k = \mu + \mu_i + \epsilon_i^k$ 
- let $\mu_i \sim \mathcal N(0, \sigma_b^2)$, and $\epsilon_i^k \sim \mathcal N(0, \sigma_e^2)$
- $ICC = \frac{\sigma_b^2}{\sigma_e^2 + \sigma_b^2}$
- $ICC \uparrow \Rightarrow $ between-group variance "contains" most of the total variance
- negative ICC? mean squared error-based estimator
---
#### Image Intraclass Correlation Coefficient (I2C2)
- simplest "multivariate extension" of ICC
- $y_i^k = \mu + \mu_i + \epsilon_i^k$
- let $\mu \sim \mathcal N(0, \Sigma_b)$ and $\epsilon_i^k \sim \mathcal N(0, \Sigma_e)$
- Wilk's $\Lambda = \frac{\det(\Sigma_b)}{\det(\Sigma_b) + \det(\Sigma_e)}$

- $I2C2 = \frac{tr(\Sigma_b)}{tr(\Sigma_b) + tr(\Sigma_e)}$

- "ratio of total variability accounted for between groups"
- Why I2C2 over Wilk's $\Lambda$? Ease-of-use for high-dimensional data
---
#### Fingerprinting Index (Finger.)
- "greedy discriminability"
- $Finger. = \mathbb P(\delta(x_i^1, x_i^2) < \delta(x_i^1, x_j^2) \;\forall\; i \neq j)$
- $\forall\; i \neq j$: this property must occur for every measurement in the second session
---
#### Distance Components (Kernel)
- "non-parametric ANOVA"
- total dispersion is the sum of between and within-sample dispersions ($B$ and $W$)

- $DISCO = \frac{\frac{B}{n - 1}}{\frac{W}{n\cdot s - n}}$

- "pseudo F" statistic

---

name:discr-limitations

### [Outline](#talk)

### Additional Content

- Discriminability
  - [Theory](#discr-theory)
  - [Other Reproducibility Statistics](#discr-other)
  - Limitations
  - [Extension: Discriminability Decomposition](#discr-extension)  
- [Causal Discrepency Testing](#causal-extra)

---

### Limitations
- experimental design is not "one-size-fits-all"
  <!-- - future scientific questions will still need to consider the question of interest -->
  <!-- - e.g., an analysis of task fMRI may not want to use a pre-processing pipeline with global signal regression, but for resting-state fMRI, this may not be an issue -->
- Discriminability is not sufficient for practical utility
  - categorical covariates are meaningful but not discriminable
  - fingerprints are discriminable but not typically biological useful
- These statistics are not immune to sample characteristics
  - confounds such as age may inflate discriminability

---

name:discr-extension
  
### [Outline](#talk)
  
### Additional Content
  
- Discriminability
  - [Theory](#discr-theory)
  - [Other Reproducibility Statistics](#discr-other)
  - [Limitations](#discr-limitations)
  - Extension: Discriminability Decomposition 
- [Causal Discrepency Testing](#causal-extra)
  
---

### Extension: Discriminability Decomposition

#### Setting
$(x_{i}^k, y_i)$ $i=1, ..., n$, $k=1,...,s$, $y_i \in$ \{$1, ..., Y$\}
- associated with each individual, I have some other categorical covariate of interest, $y_i$, taking one of $Y$ possible values
- Can the population discriminability be decomposed as a sum of the within-group discriminabilities?

---

### Within-Group Discriminability

- Let $D(y) = \mathbb P(\delta(x_i^k, x_i^{k'}) < \delta(x_i^k, x_j^{k''}) | y_i, y_j = y)$ 
- $D(y)$ is the group discriminability for group $y$
- "How discriminable are samples from group $y$?"
--
- Note that $W = \mathbb P(\delta(x_i^k, x_i^{k'}) < \delta(x_i^k, x_j^{k''}) | y_i= y_j)$= $\frac{\mathbb P(\delta(x_i^k, x_i^{k'}) < \delta(x_i^k, x_j^{k''}) , y_i = y_j)}{\mathbb P(y_i = y_j)}$ by def conditional probability

--
- Let $w(y) = \mathbb P(y_i=y_j = y)$ denote the within-group weights 
- With $\omega = \sum_y w(y)$, then:

 $W = \frac{1}{\omega}\sum_y w(y) D(y)$ is the within-group Discriminability

---
### Between-Group Discriminability
- Let $D(y, y') = P(\delta(x_i^k, x_i^{k'}) < \delta(x_i^k, x_j^{k''}) | y_i = y, y_j = y')$
- $D(y, y')$ is the between-group discriminability for groups $y$ and $y'$
- "How discriminable are samples from group $y$ vs group $y'$, and vice versa?"

--
- Note that $B = \mathbb P(\delta(x_i^k, x_i^{k'}) < \delta(x_i^k, x_j^{k''}) | y_i\neq  y_j)$= $\frac{\mathbb P(\delta(x_i^k, x_i^{k'}) < \delta(x_i^k, x_j^{k''}) , y_i \neq y_j)}{\mathbb P(y_i \neq y_j)}$ by def conditional probability

--
- Let $b(y, y') = \mathbb P(y_i = y, y_j = y')$ denote the between group weights 
- With $\beta = \sum_{y\neq y'} b(y,y')$, then:

$B = \frac{1}{\beta}\sum_{y \neq y'}b(y,y')D(y,y')$ is the between-group Discr.

---
### Discriminability Decomposition

- $D = \omega W + \beta B$
- Population discriminability is a weighted sum of within and between-group Discriminabilities
- Can look at how the within, or between, group discriminabilities compare
- $\frac{W}{D}$ ratio of within-group Discriminability and pop. discriminability
- $\frac{B}{D}$ ratio of between-group Discriminability and pop. discriminabillity
- are certain groups more discriminable than others?
- are certain between-group discriminabilities greater than others?
- "ANOVA-esque" or DISCO-esque"

---

name:causal-extra

### [Outline](#talk)

### Additional Content

- [Discriminability](#discr-extra)
- Causal Discrepency Testing
  - [Background](#causal-back)
  - [Conditional causal discrepency testing](#causal-cond)
  - [Simulations](#causal-sims)
  - [Limitations (detection)](#causal-detect-lims)
  - [Limitations (estimation)](#causal-rem-lims)

---

name:causal-back

### [Outline](#talk)

### Additional Content

- [Discriminability](#discr-extra)
- Causal Discrepency Testing
  - Background
  - [Conditional causal discrepency testing](#causal-cond)
  - [Simulations](#causal-sims)
  - [Limitations (detection)](#causal-detect-lims)
  - [Limitations (estimation)](#causal-rem-lims)

---

### The average treatment effect

$\gamma \triangleq ATE = \mathbb E[Y_i(2) - Y_i(1)]$

$H_0 : \gamma = 0$ against $H_A : \gamma \neq 0$

- .ye[Fundamental problem of causal inference]: we observe $Y_i$, not $Y_i(t)$

---

### "Standard causal assumptions"

- Consistency: $Y_i = \\sum_t Y_i(t) \\mathbb I\\{T_i = t\\}$
  - we only observe one potential outcome (the rest are "missing")
--

- Positivity: $P(T_i  = t | X_i = x) > 0$ for all $x$
  - covariate distributions "overlap"
--

- Ignorability: $\left(Y_i(1), ..., Y_i(K)\right) \perp T_i | X_i$
  - missing data does not depend on missing data
  - Did we "observe" all impactful variables?
--

- No interference: treatments of units do not impact potential outcomes of other units

---

### Causal assumptions allow us to describe potential outcomes

Under standard causal assumptions, $\mathbb E[Y_i(t)] = \mathbb E\left[\mathbb E[Y_i | T_i = t, X_i]\right]$
  - uses: .ye[$G$-computation formula]
  - convenience: $\mathbb E[Y_i | T_i = 1, X_i]$ can be estimated

--

$\gamma \triangleq ATE = \mathbb E[Y_i(2) - Y_i(1)]$

$\Rightarrow \gamma = \mathbb E[\mathbb E[Y_i | T_i = 1, X_i] - \mathbb E[Y_i | T_i = 1, X_i]]$

---

### Simulated example

<center>![:scale 80%](images/causal/task.png)</center>

- assumption: age and malnutrition are the only factors that impact height

---

### Simulated example

<center>![:scale 80%](images/causal/data.png)</center>

- Causal assumptions?

---

### Simulated example

<center>![:scale 80%](images/causal/ate_ex_pos.png)</center>

- Run linear regression, look for offset
  - Offset "is" $\hat \gamma$

---

### "Unequal" impact across covariates?

<center>![:scale 80%](images/causal/cate_mot.png)</center>

---

### Conditional ATE

$\gamma_x \triangleq CATE(x) = \mathbb E[Y_i(2) - Y_i(1) | X = x]$

$H_0 : \gamma_x = 0$ against $H_A : \gamma_x \neq 0$

- Standard assumptions: $\mathbb E[Y_i(t) | X = x] = \mathbb E[Y_i | T_i = t, X = x]$ 
  - as before, can be estimated (and tested)

---

### "Unequal" impact across covariates?

<center>![:scale 80%](images/causal/cate_task.png)</center>
- problem: higher order moments?

---

name:causal-cond

### [Outline](#talk)

### Additional Content

- [Discriminability](#discr-extra)
- Causal Discrepency Testing
  - [Background](#causal-back)
  - Conditional causal discrepency testing
  - [Simulations](#causal-sims)
  - [Limitations (detection)](#causal-detect-lims)
  - [Limitations (estimation)](#causal-rem-lims)

---

### Causal conditional discrepancy

- .ye[Causal conditional discrepancy]:

$F\_{Y\_i(k) | x} \neq F\_{Y\_i(l) | x}$

- for two "exposures" $k$ and $l$, there is a "discrepancy" in the potential outcome distributions for some covariate level $x$

--
- problem: cannot determine from data (some potential outcomes $Y_i(t)$ are typically missing)

---

### Conditional discrepancy

.ye[Conditional discrepancy]:

$F\_{Y\_i | k, x} \neq F\_{Y\_i | l, x}$

- can determine from observed data (statements about observed $Y_i$)

--

##### Lemma

Under standard causal assumptions, the following two tests are equivalent:

1. $H\_0 : F\_{Y\_i(k) | x} = F\_{Y\_i(l) | x}$ against $H\_A: F\_{Y\_i(k) | x} \neq F\_{Y\_i(l) | x}$
2. $H\_0 : F\_{Y\_i | k, x} = F\_{Y\_i | l, x}$ against $H\_A: F\_{Y\_i | k, x} \neq F\_{Y\_i | l, x}$

--
- Tests for causal conditional discrepancies are equivalent to conditional discrepancies

---

### Testing for causal discrepancies

Related: Conditional independence (CI) testing

$H\_0 : F\_{Y\_i, V\_i | x} = F\_{Y\_i | x}F\_{V\_i | x}$ against $H\_A : F\_{Y\_i, V\_i | x} \neq F\_{Y\_i | x}F\_{V\_i | x}$
- if $V\_i$ is nominal, this is a conditional discrepancy test

##### Remark (known)

If $V\_i$ is nominal, a CI test is equivalent to a conditional discrepancy test.

##### Corollary

Adding causal assumptions, a CI test is equivalent to a causal conditional discrepancy test.

---

##### Known
1. CI tests apply readily to high-dimensional data
2. CI tests apply to multiple exposures (lemma)
3. (Asymptotically) consistent test for causal conditional discrepancy testing (corollary)
  - works with .ye[enough] data

--

##### Unknown
  - Finite sample performance?
  - Impact of group imbalance on inference?
---


name:causal-sims

### [Outline](#talk)

### Additional Content

- [Discriminability](#discr-extra)
- Causal Discrepency Testing
  - [Background](#causal-back)
  - [Conditional causal discrepency testing](#causal-cond)
  - Simulations
  - [Limitations (detection)](#causal-detect-lims)
  - [Limitations (estimation)](#causal-rem-lims)

---

### Simulations

##### Settings

- $n = 100$ samples in $ \geq 2$ batches
- $d=10$ (low dimensional) or $d=101$ (high dimensional)
- Settings: non-linear, non-monotone, second order, and multi-class

<center>![:scale 100%](images/causal/Sigmoidal.png)</center>

---

### Simulations

##### Key Aspects

- Balance: how well do the covariates overlap?
- Effect size $\Delta$: how different is the data between batches?
  - $H_0 :$ no difference in batch distributions
  - $H_A :$ difference in batch distributions

<center>![:scale 100%](images/causal/Sigmoidal.png)</center>

---

### Question 1: validity

- Fix $\Delta = 0$ ($H_0$ is true)
- for all tests, varying balance from $0.2$ (low balance) to $1.0$ (complete balance):
  - estimate type I error rate over $r=100$ trials

--
- Valid test: Type I error rate $\leq \alpha = 0.05$
- total of 80 possible settings (10 levels of "covariate balance" $\times$ 8 simulation settings)
  - cMANOVA cannot be used in high dimensional regimes (40 total settings)
  - KernelCDTest cannot be used in $>2$ exposure settings (20 total settings)
  - "Valid": type I error rate within 1 SE of $.05$

---

### Validity testing

<br/>


<center>![:scale 100%](images/causal/validity.png)</center>

- Causal cDCorr and KernelCDTest are only valid strategies
- Causal cDCorr only test which works on $>2$ exposure settings


---

### Question 2: power

- $H_A$ is true for $\Delta > 0$ (there is an effect)
- for all tests, vary $\Delta$ from $0$ to $1.0$ (outcome/covariate distributions very different across exposures):
  - estimate statistical power over $r=100$ trials

--
- Powerful test: statistical power increasing (to $\approx 1$) as $\Delta$ increases

---

### Power testing

<center>![:scale 95%](images/causal/powers.png)</center>

- Causal $\texttt{cDCorr}$ is only approach powerful in all contexts (and at or near highest in any one context)

---

name:causal-detect-lims

### [Outline](#talk)

### Additional Content

- [Discriminability](#discr-extra)
- Causal Discrepency Testing
  - [Background](#causal-back)
  - [Conditional causal discrepency testing](#causal-cond)
  - [Simulations](#causal-sims)
  - Limitations (detection)
  - [Limitations (estimation)](#causal-rem-lims)

---

---

name:causal-rem-lims

### [Outline](#talk)

### Additional Content

- [Discriminability](#discr-extra)
- Causal Discrepency Testing
  - [Background](#causal-back)
  - [Conditional causal discrepency testing](#causal-cond)
  - [Simulations](#causal-sims)
  - [Limitations (detection)](#causal-detect-lims)
  - Limitations (estimation)

---

</textarea>
<!-- <script src="https://gnab.github.io/remark/downloads/remark-latest.min.js"></script> -->
<!-- <script src="remark-latest.min.js"></script> -->
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.3/katex.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.3/contrib/auto-render.min.js"></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.3/katex.min.css">
<script type="text/javascript">

  var options = {};
  var renderMath = function () {
    renderMathInElement(document.body);
    // or if you want to use $...$ for math,
    renderMathInElement(document.body, {
      delimiters: [ // mind the order of delimiters(!?)
        { left: "$$", right: "$$", display: true },
        { left: "$", right: "$", display: false },
        { left: "\\[", right: "\\]", display: true },
        { left: "\\(", right: "\\)", display: false },
      ]
    });
  }

  remark.macros.scale = function (percentage) {
    var url = this;
    return '<img src="' + url + '" style="width: ' + percentage + '" />';
  };

  // var slideshow = remark.create({
  // Set the slideshow display ratio
  // Default: '4:3'
  // Alternatives: '16:9', ...
  // {
  // ratio: '16:9',
  // });

  var slideshow = remark.create(options, renderMath);


</script>
</body>

</html>