<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>FNGS Final Project - Neurodata</title>

		<meta name="description" content="A framework for easily creating beautiful presentations using HTML">
		<meta name="author" content="Hakim El Hattab">

		<meta name="apple-mobile-web-app-capable" content="yes">
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<link rel="stylesheet" href="../reveal.js/css/reveal.css">
		<link rel="stylesheet" href="../reveal.js/css/theme/black.css" id="theme">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="../reveal.js/lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<!--[if lt IE 9]>
		<script src="../reveal.js/lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				<section>
					<h1>FNGS</h1>
					<h3>A One-Click Pipeline for the Automated Acquisition of Functional MRI Connectomes</h3>
					<p>
						<small>Created by <a href="http://ericwb.me">Eric Bridgeford</a>, Tanay Agarwal, Eric Walker / Contact: <a href="http://github.com/ebridge2">@ebridge2</a></small>
					</p>
				</section>

				<section>
					<section>
						<h2>Q: What is functional Neuroimaging?</h2>
					</section>
					<section>
						<h3>BOLD Signal</h3>
						<ul>
							<li>Blood-Oxygen Level Dependent imaging</li>
							<li>When brain region becomes more active, body sends more oxygenated blood</li>
						</ul>
						<img src="../img/thesis/hemo.png" />
					</section>
					<section>
						<h3>Hemodynamic Response</h3>
						<ul>
							<li>Deoxy-hemo has different MR signature than oxy-hemo</li>
							<li>End up with this differential contrast when a brain region becomes active</li>
							<li>Blood response pattern called Hemodynamic Response Function (HRF)</li>
						</ul>
						<img src="../img/thesis/hrf.png" />
					</section>
					<section>
						<h3>4D Imaging</h3>
						<ul>
							<li>Image the BOLD value in each volume-pixel (voxel)</li>
							<ul>
								<li>$2\times 2\times 2\; mm^3$ squares we measure the BOLD contrast in</li>
							</ul>
							<li>Take a 3D volume of a brain per timepoint</li>
							<li>$4D$ image: $3$ spatial $+$ $1$ temporal (time)</li>
						</ul>
						<img src="../img/thesis/4D.jpeg" />
					</section>
					<section>
						<h3>Anatomical Imaging</h3>
						<ul>
							<li>high resolution, 3D anatomical image taken with each subject</li>
							<li>Same true brain shape, different resolution</li>
							<li>Allows a look at anatomical features themselves</li>
						</ul>
						<img src="../img/thesis/anat.png" width="40%"/>
					</section>
				</section>

				<section>
					<section>
						<h2>Q: What are the computational restrictions hampering modern neuroscience?</h2>
					</section>

					<section>
						<h3>Throughput Problems</h3>
						<ul>
							<li>Processing brain scans is computationally expensive</li>
							<ul>
								<li>A brain scan has between 2-800 observations of about $10^6$ features</li>
								<li>CPU/RAM usage is heavy</li>
								<li>It is essentially a prerequisite to have a cluster</li>
							</ul>
						</ul>
					</section>

					<section>
						<h3>Software and Hardware Constraints</h3>
						<ul>
							<li>Many users who want connectomes won't be able to setup a cluster</li>
							<li>Requisite software dependencies themselves require computer expertise</li>
						</ul>
					</section>
					<section>
						<h3>Choice of Pipeline</h3>
						<ul>
							<li>Hundreds of Processing options</li>
							<ul>
								<li>Difficulty quantifying a "good" pipeline</li>
								<li>Most studies are single-dataset: few meganalyses</li>
							</ul>
							<li>Choice of pipeline is highly nonconvex: best options locally might not be best globally</li>
						</ul>
					</section>
				</section>

				<section>
					<section>
						<h2>Q: How do we Choose a "Good" Pipeline?</h2>
					</section>
					<section>
						<h3>Desiderata</h3>
						<ul>
							<li>If I scan everybody in a room twice and acquire functional connectomes, will I be able to identify the pairs of connectomes?</li>
							<li>Identify = Will everybody's closest connectome (as defined by frobenius norm) be their alternate connectome?</li>
						</ul>
					</section>
					<section>
						<h3>Discriminability</h3>
						<ul>
							<li><a href="https://github.com/neurodata/discriminability">Discriminability</a> quantifies this</li>
								<ul>
									<li>Low Discriminability: all connectomes look the same</li>
									<li>High Discirminability: repeated connectomes of same subject look most similar</li>
								</ul>
							<li>brute-force search over many popular pipeline options (64 total) to help us understand pipeline performance</li>
						</ul>
					</section>
				</section>

				<section>
					<section>
						<h2>FNGS Pipeline</h2>						
				    	<img src="../img/thesis/pipeline.png" border="0"/>
					</section>
				</section>

				<section>
					<section>
						<h1>Preprocessing</h1>	
				    	<img src="../img/thesis/preproc.png" style="width: 80%; "/>
				    	<img src="../img/thesis/bottom.png" border="0" style="width: 60%;"/>
					</section>

					<section>
						<h3>Motion Correction</h3>	
						<ul>
							<li>Problem: Scanning session is 3 to 10 minutes </li>
							<ul>
								<li>Subjects can rotate and move (translate) their heads</li>
							</ul>
							<li>Given: Brain shape is fixed: no need to rescale</li>
							<li>Solution: Rigid Affine Transformation with 6 degrees of freedom</li>
							<ul>
								<li>Estimate x, y, z translation and x, y, z rotation at each timepoint</li>
							</ul>
						</ul>
					</section>

					<section>
						<h3>Slice Timing Correction</h3>
						<ul>
							<li>Problem: a 3D volume is taken in 2D slices over the course of 2-3 seconds</li>
							<li>Given: we know exactly when each slice is taken per timepoint</li>
						</ul>
				    	<img src="../img/thesis/un_stc.png" border="0" style="width: 20%;"/>
				    	<img src="../img/thesis/un_stc_overlay.png" border="0" style="width: 20%;"/>
				    	<img src="../img/thesis/stc_graph.png" border="0" style="width: 55%;"/>
					</section>

					<section>
						<h3>Slice Timing Correction</h3>
						<ul>
							<li>Solution: Sinc Interpolation to center timeseries about each discrete timepoint</li>
						</ul>
				    	<img src="../img/thesis/un_stc.png" border="0" style="width: 30%;"/>
				    	<img src="../img/thesis/stc.png" border="0" style="width: 30%;"/>
					</section>

					<section>
						<h3>Preprocessing Improves Discriminability</h3>
						<img src="../img/thesis/no_preproc_preproc.png" border="0"/>
						<ul>
							<li>p-value of difference: $p = .01$</li>
						</ul>
					</section>
				</section>

				<section>
					<section>
						<h1>Registration</h1>
				    	<img src="../img/thesis/reg.png" style="width: 80%; "/>
						<img src="../img/thesis/bottom.png" border="0" style="width: 60%;"/>
					</section>
					<section>
						<h2>Registration Procedure</h2>
						<ul>
							<li>Self-registration should be near-perfect</li>
							<ul>
								<li>The functional scan has the same true shape as the T1w anatomical scan</li>
								<li>Only difference is the resolution and modality of the images</li>
							</ul>
							<li>Use the T1w to align with the template, since we can use anatomically precise landmarking while registering</li>
						</ul>
					</section>
					<section>
						<h3>Stepwise-Alignment offers fail-safe registration</h3>
						<img src="../img/thesis/distorted.png" style="width: 40%;"/>
						<img src="../img/thesis/no_distortion.png" style="width: 40%;"/>
						<ul>
							<li>If a brain fails on an aggressive strategy like FNIRT, fall back on a gentle strategy like FLIRT</li>
						</ul>
					</section>
				</section>
				<section>
					<section>
						<h3>Nuisance Correction</h3>
				    	<img src="../img/thesis/nuis.png" style="width: 80%; "/>
				    	<img src="../img/thesis/bottom.png" border="0" style="width: 60%;"/>
					</section>
					<section>
						<h3>Nuisance Variables</h3>
						<ul>
							<li>Scanner heat up: quadratic drifting of the timeseries</li>
							<li>Temporal physiological noise: heart beat, etc.</li>
							<ul>
								<li>physiological factors that impact our signal but are not from brain activity</li>
							</ul>
							<li>T1 effect: magnetic dynamics take a few seconds to stabilize</li>
						</ul>
					</section>
					<section>
						<h3>Nuisance Correction removes nuisance variables</h3>
						<ul>
							<li>GLM to estimate best-fit quadratic</li>
							<ul>
								<li>Neurological signal known to not behave globally quadratically, so a best-fit quadratic will not remove neurological signal</li>
							</ul>
							<li>Highpass filter to remove low-frequency drift</li>
							<ul>
								<li>Brain activity is on order of $0.1$ Hz, so high-pass over $0.01$ Hz for a generous threshold</li>
							</ul>
							<li>Throw away first 10 seconds of every scan</li>
						</ul>
					</section>

					<section>
						<h2>TODO: Insert Demonstration that Discriminability or Some other statistic increases after nuisance correction</h2>
					</section>
				</section>

				<section>
					<section>
						<h2>Connectome Estimation</h2>
				    	<img src="../img/thesis/con_est.png" style="width: 80%; "/>
				    	<img src="../img/thesis/bottom.png" border="0" style="width: 60%;"/>
					</section>
					<section>
						<h3>Downsampling</h3>
						<ul>
							<li>Anatomically and functionally defined parcellations that are labelled by brain region</li>
							<li>Spatially downsample each 3D volume for each timepoint</li>
							<li>$B \in \mathbb{R}^{10^6 \times t}$ for $t$ observations, $10^{6}$ features/voxels</li>
							<li>$D = downsample(B) \in \mathbb{R}^{r \times t}$ where $r$ is between 20 to 300 generally depending on the spatial parcellation we use</li>
							<li>$C = cor(D) \in \mathbb{R}^{r \times r}$ representing our adjacency matrix or functional connectome</li>
						</ul>
					</section>
					<section>
						<h3>Timeseries</h3>
						<img src="../img/thesis/ts.png" border="0"/>						
					</section>
					<section>
						<h3>Correlation Matrix/Connectome</h3>
						<img src="../img/thesis/corr.png" border="0"/>						
					</section>
				</section>

				<section>
					<section>
						<h1>Advantages of FNGS</h1>
					</section>
					<section>
						<h3>FNGS has low memory and CPU requirements</h3>						
						<img src="../img/thesis/perf.png" style="width: 80%; "/>
						<ul>
							<li>Single threaded: easy to parallelize</li>
						</ul>
					</section>

					<section>
						<h3>FNGS is more user-friendly than comparable pipelines</h3>
						<ul>
							<li>Compared to a Nipype Pipeline, FNGS is:</li>
							<ul>
								<li>Easy to Use: no config files</li>
								<li>Intuitive: No convoluted output structure</li>
								<li>Robust: no chance of picking a bad pipeline</li>
								<li>Scalable on Cloud: Nipype pipelines must be individually tuned to a specific cluster software</li>
							</ul>
						</ul>
					</section>

					<section>
						<h3>FNGS performs comparably to reference pipelines</h3>
						<img src="../img/thesis/cpac_vs_fngs.png" border="0"/>
					</section>
				</section>


				<section>
					<section>
						<h2>Q: How do we make deployment easy?</h2>
					</section>

					<section>
						<h2>FNGS Pipeline</h2>						
						<img src="../img/thesis/pipeline.png" border="0"/>
					</section>

					<section>
						<h3>Docker Containers simplify dependency constraints</h3>
						<ul>
							<li>software container with all dependencies associated with our pipeline</li>
							<li>user does not have to install anything locally (except for the docker controller)</li>
							<li>All drivers and controllers, for cloud or local usage, can be called from here with one click</li>
						</ul>
					</section>

					<section>
						<h3>FNGS Offers multiple options for deployment</h>
						<ul>
							<li><a href="https://github.com/neurodatadesign/local_bids.md">Local Deployment</a></li>
							<li><a href="https://github.com/neurodatadesign/local_cloud.md">Command Line Cloud Deployment</a></li>
							<li><a href="https://github.com/neurodatadesign/website_cloud.md">Website Deployment</a></li>
						</ul>
					</section>

				</section>
				<section>
					<section>
						<h2>Real Data Experiments</h2>
					</section>
					<section>
						<h3>Single Dataset Analysis  shows high discriminability</h3>
						<ul>
							<li>270 scans</li>
							<li>Analyze in parallel: approximately $\$15$, about $2.5$ hours</li>
							<li>Compute Discriminability between subjects using <a href="https://github.com/ebridge2/Discriminability">Discriminability package</a></li>
							<li>Goal: Are the connectomes differentiable between subjects?</li>
						</ul>
					</section>

					<section>
						<h3>Average Connectome, $n=108$</h3>
						<img src="../img/thesis/corr.png" border="0"/>						
					</section>
					<section>
						<h3>Single Dataset Analysis shows high discriminability</h3>
						<img src="../img/thesis/hnu.png" border="0"/>
					</section>

					<section>
						<h3>Harmonized Analysis reveals quantitative variations in timeseries</h3>
						<ul>
							<li>$n=794$ scans collected at $6$ different sites</li>
							<li>Similar scanners and parameter selection</li>
							<li>Analyze in parallel: approximately $\$50$, and about $7$ hours</li>
							<li>Goal: Are the connectomes differentiable between Scan Site?</li>
						</ul>
					</section>

					<section>
						<h3>Harmonized Analysis reveals quantitative variations in timeseries</h3>
						<img src="../img/thesis/dataset.png" border="0"/>
						<ul>
							<li>Theoretical random discriminability score: $0.248$</li>
							<li>p-value of difference: $p = 0.001$</li>
							<li>Scanning site plays a heavy role in quantitative properties</li>
						</ul>
					</section>

					<section>
						<h3>Signal Subgraphing to assess task fMRI</h3>
						<ul>
							<li>Statistical Question: Can we identify the sub-network, or sub-graph, that variest between experimental conditions?</li>
							<li>Related Question: How many timepoints, and how many observations, do we need to get a good prediction?</li>
							<li>Constraints: Graphs are binarized</li>
							<li>Parameters</li>
							<ul>
								<li>Number of edges in the subgraph</li>
							</ul>
							<li>Quantification: $\hat{L}$, the misclassification rate</li>
						</ul>
					</section>

					<section>
						<h3>Simulation Setting</h3>
						<ul>
							<li>Given: 2 Classes of Covariance Matrices and Mean Vectors</li>
							<li>Identify 100 most variant edges, and define these edges as subgraph</li>
							<li>Sample $t$ timepoints and form correlation matrix per observation</li>
							<li>Binarize collection of Correlation matrices</li>
							<li>Run Signal Subgraphing, and identify the ranges of "good-performing $t, n$</li>
							<li>$\hat{L} = \textrm{min}_{t, n} {L}(C_{t, n} | S(C_{t, n}))$</li>
						</ul>
					</section>

					<section>
						<h3>Signal Subgraphing finds a good approximation of the actual subgraph</h3>
						<img src="../img/thesis/ssg_sim.png" border="0"/>
					</section>
				</section>

				<section>
					<section>
						<h3>Future Goals</h3>
						<ul>
							<li>Improve Nuisance Correction Further</li>
							<ul>
								<li>Quantify "Bad Nuisance Correction"</li>
							</ul>
							<li>Implement LDDMM (Large Deformation Diffeomorphic Metric Mapping) for Registration</li>
							<li>Explore Multigraphs</li>
						</ul>
					</section>

					<section>
						<h3>Acknowledgements</h3>
						<ul>
							<li>Team: Eric Bridgeford, Tanay Agarwal, Eric Walker</li>
							<li>Dr. Josh Vogelstein: PI</li>
							<li>Greg Kiar: PhD student at McGill University</li>

							<li>Neurodata</li>
						</ul>
					</section>

					<section>
						<h3>Important Links</h3>
						<ul>
							<li>Live Webservice: <a href="cortex.jhu.edu:8003">FNGS homepage</a></li>
							<li>Docker Cloud: <a href="https://hub.docker.com/r/ericw95/fngs/">FNGS pipeline</a>
							<li>Docker Web Service: <a href="https://hub.docker.com/r/ericw95/fngs-webapp/">FNGS web service</a>
							<li>Weekly Updates: <a href="https://github.com/neurodatadesign/fngs">FNGS repo</a></li>
							<li>Code: <a href="https://github.com/neurodata/ndmg">NDMG pipeline</a> (contains FNGS pipeline)</li>
						</ul>
						</p>
					</section>
					<section>
						<h3>Questions?</h2>
						<ul>
							<li>TODO: Demo running in cloud</li>
						</ul>
						<p>
						<small>Created by <a href="http://ericwb.me">Eric Bridgeford</a>, Tanay Agarwal, Eric Walker / Contact: <a href="http://github.com/ebridge2">@ebridge2</a></small>
						</p>
					</section>
				</section>

			</div>

		</div>

		<script src="../reveal.js/lib/js/head.min.js"></script>
		<script src="../reveal.js/js/reveal.js"></script>

		<script>

			// More info https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,

				math: {
					// mathjax: 'http://cdn.mathjax.org/mathjax/latest/MathJax.js',
					config: 'TeX-AMS_HTML-full'
				},

				transition: 'slide', // none/fade/slide/convex/concave/zoom

				// More info https://github.com/hakimel/reveal.js#dependencies
				dependencies: [
					{ src: '../reveal.js/plugin/math/math.js', async: true },
					{ src: '../reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: '../reveal.js/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: '../reveal.js/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: '../reveal.js/plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: '../reveal.js/plugin/zoom-js/zoom.js', async: true },
					{ src: '../reveal.js/plugin/notes/notes.js', async: true }
				]
			});

		</script>

	</body>
</html>
