<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>Random Forests for Accelerometer Data Classification</title>

		<meta name="description" content="Using Random Forests for Classification of Accelerometer Data">
		<meta name="author" content="Hakim El Hattab">

		<meta name="apple-mobile-web-app-capable" content="yes">
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<link rel="stylesheet" href="../../../reveal.js/css/reveal.css">
		<link rel="stylesheet" href="../../../reveal.js/css/theme/black.css" id="theme">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="../../../reveal.js/lib/css/zenburn.css">
		<link rel="shortcut icon" type="image/png" href="./img/neurodata.png"/>
		<link rel="shortcut icon" type="image/png" href="./img/neurodata.png"/>

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>


		<!--[if lt IE 9]>
		<script src="../reveal.js/lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				<style>
				    .container { 
				    font-size:0}

				    .left { 
				    display: inline-block; 
				    width: 60%; 
				    font-size:1rem; /* IE9+ */
				    }

				    .ie7 .left {font-size:16px; display:inline; zoom:1}

				    .ie8 .left {font-size:16px}

				    .right { 
				    display: inline-block; 
				    width: 38%; 
				    font-size:1rem; /* IE9+ */
				    }

				    .ie7 .right {font-size:16px; display:inline; zoom:1}

				    .ie8 .right {font-size:16px}

				</style>
 
				<section>
					<!-- <h1>NDMG</h1> -->
					<h3>Using Random Forests for Accelerometer Data Classification</h3>
					<p>
						<small>Presented by Jiyang Wen and Eric Bridgeford</small>
					</p>
					<p></p>
					<p>
						<small>Follow the slides: <a href="ericwb.me/lectures/class/bayesian_ss/bayesian_final.html">ericwb.me/lectures/class/bayesian_ss/bayesian_final.html</a></small>
					</p>
				</section>
				<section>
					<h2>What we will cover</h2>
					<ul>
						<li>Introduction to Decision Trees</li>
						<li>Introduction to Random Forests</li>
						<li>Challenges of the Accelerometer Data and Feature Screening</li>
						<li>Next Steps</li>
					</ul>
				</section>
				
				<section>
					<section>
						<h1>Decision Trees</h1>
					</section>

					<section>
						<h3>What is a Decision Tree?</h3>
						<ul>
							<li>A decision tree is a set of rules and actions</li>
							<li>Intuitive: Natural approach to problem solving</li>
						</ul>
						<img src="./img/dec_tree_basic.jpg" alt="Decision Tree Example">
					</section>

					<section>
						<ul>
							<li>We're grad students; of course we don't have 25 dollars</li>
						</ul>
						<img src="https://media3.giphy.com/media/3o7buhm1O1bOJV4ZWM/giphy.gif" alt="burger">
					</section>

					<section>
						<h3>What Did we Just Do?</h3>
						<ul>
							<li>Goal: Deciding how to eat</li>
							<li>Nodes: Propose a question</li>
							<ul>
								<li>Construct a "split": Do I continue along the tree to the left, or the right?</li>
							</ul>
							<li>Leaves: Decisions</li>
							<ul>
								<li>I'm hungry, and I don't have $25, so I buy a hamburger</li>
							</ul>
						</ul>
					</section>
					<section>
						<h3>Extending Decision Trees to Continuous Data</h3>
						<img src="./img/xor_setup.png" alt="XOR Setup" height="360" width="580">
					</section>
					<section>
						<h3>Making a Split</h3>
						<ul>
							<li>Check $d_j = 1, ..., p$, trying $\tau_{ij} = (X_{ij})_i$</li>
							<li>Find the split $(d^*_{(1)}, \tau^*_{(1)})$ that minimizes the class impurity</li>
						</ul>
						<img src="./img/xor_tree_first.png" alt="XOR Split" height="230" width="420">
						<img src="./img/xor_split.png" alt="XOR Split" height="230" width="420">  
					</section>
					<section>
						<h3>Obtaining a Decision Rule</h3>
						<ul>
							<li>Keep pushing the splits down, until we reach a maximum depth, or there are no more samples</li>
							<li>The resulting partitions/splits form the "decision rule"</li>
						</ul>
						<img src="./img/xor_tree_complete.png" alt="XOR Done" height="230" width="420">
						<img src="./img/xor_done.png" alt="XOR Done" height="230" width="420">  
					</section>
				</section>

				<section>
					<section>
						<h1>From Trees to Forests</h1>
					</section>
					<section>
						<h3>How can we Augment the Decision Tree?</h3>
						<ul>
							<li>Clear that the Decision Tree Approach is a powerful foundation</li>
							<ul>
								<li>Many classes of supervised learning algorithms can't handle the XOR Problem</li>
							</ul>
							<li>We are often concerned with the $p \gg 1$ case</li>
							<ul>
								<li>Decision Trees tend to overfit</li>
							</ul>
							<li>How can we leverage the power of the decision tree, but improve generalizability?</li>
						</ul>
					</section>
					<section>
						<h3>Planting a Forest</h3>
						<ul>
							<li>Bootstrap AGGregating (bagging): Given $n$ points, sample $n'_k$ uniformly with replacement for $k = 1, ..., m$</li>
							<ul>
								<li>Train $m$ decision trees on the bootstrapped samples</li>
								<li>Instead of trying all features, try $d \ll p$ of them</li>
							</ul>
						</ul>
					</section>
					<section>
						<h3>Majority Rules</h3>
							<li>let $p_k(x)$ denote the predicted class for $x$ by tree $k$</li>
							<ul>
								<li>$\hat y(x) = \textrm{argmax}_{p}\sum_{i = 1}^k\mathbb{I}\{p_k(x) = p\}$</li>
							</ul>
					</section>

					<section>
						<h3>Example Forest Prediction</h3>
						<img src="https://cdn-images-1.medium.com/max/1554/1*i0o8mjFfCn-uD79-F1Cqkw.png" alt="RF">
					</section>
				</section>

				<section>
					<section>
						<h3>Challenges of the Accelerometer Data and Feature Screening</h3>
					</section>

					<section>
						<h3>Making Sense of Lots (and lots) of Data Points</h3>
						<ul>
							<li>Each subject has about 2 <i>million</i> time points taken from any of 4 locations</li>
							<ul><li>left wrist, left hip, left ankle, right ankle</li>
								<li>each time point is labelled according to the activity being performed</li></ul>
							<li>Problem: the data are noisy, and alone may not be informative for a classification task</li>
						</ul>
					</section>

					<section>
						<h3>Deciding what will be Informative</h3>
						<ul>
							<li>Naive Idea: downsample by time windows of width $w$</li>
							<li>Goal: Given a time window $i$, compute summary measures $X_i$</li>
							<ul><li>mean, quantiles, min, max of x, y, z, azimuth, vector magnitude, elevation</li>
								<li>vmc</li>
								<li>Attempt at both the aggregate (across location) and individual accelerometer location levels</li></ul>
						</ul>
					</section>

					<section>
						<h3><a href="https://elifesciences.org/articles/41690">Multiscale Generalized Correlation</a></h3>
						<ul>
							<li>Goal is to characterize whether the naive summary measures we have computed are informative</li>
							<ul>
								<li>Further question: can we detect an effect using only a single accelerometer location?</li>
							</ul>
							<li>Independence Test: Does there exist a dependency between $X_i$ and $Y_i$?</li>
							<ul>
								<li>Future Idea: "Feature Screening"</li>
							</ul>
						</ul>
					</section>

					<section>
						<h3>Procedure for Effect Size Investigation</h3>
						<ul>
							<li>For accelerometer location $L$ (+All), resolution $R$, and activity $A$ (+All)</li>
							<ol>
							<li>Compute the summary metrics $X_i$ at resolution $R$ and location $L$</li>
							<li>Let $Y_i = \mathbb I(task_i = A)$</li>
							<li>Compute $MGC_{L,R,A}$ and $p$-value</li>
							</ol>
							<li>Break up and Fisher correct the $p$-values</li>
						</ul>
					</section>

					<section>
						<h3>Feature Screening Results (by Accelerometer)</h3>
					</section>

					<section>
						<h3>Procedure for Classification Evaluation</h3>
						<ul>
							<li>For accelerometer location $L$ (+all), resolution $R$</li>
							<ol>
								<li>Perform $10$-fold cross validation, to obtain misclassification rate $e_{L,R}$</li>
								<li>Train on all of the data, producing trained forest $F_{L,R}$</li>
								<li>Compute feature importance $I_{L,R,j}$ for each feature $j$ on forest $F_{L,R}$</li>
							</ol>
							<li>Make sure forests have love, tenderness, and care (and 96 cores/1 TB RAM)</li>
						</ul>
					</section>
					<section>
						<h3>Classification Performance (by Accelerometer)</h3>
					</section>
					<section>
						<h3>Feature Importances (by Accelerometer)</h3>
					</section>
				</section>


				<section>
					<h3>Package References</h3>
					<ul>
						<li><a href="https://github.com/ebridge2/r-mgc">Multiscale Generalized Correlation</a></li>
						<li><a href="https://github.com/ebridge2/SPORF">Sparse Projection Oblique Random Forest</a></li>						
					</ul>
				</section>
				<section>
					<h3>Questions?</h3>
				</section>

			</div>

		</div>

		<script src="../../../reveal.js/lib/js/head.min.js"></script>
		<script src="../../../reveal.js/js/reveal.js"></script>

		<script>

			// More info https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,

				math: {
					// mathjax: 'http://cdn.mathjax.org/mathjax/latest/MathJax.js',
					config: 'TeX-AMS_HTML-full'
				},

				transition: 'slide', // none/fade/slide/convex/concave/zoom

				// More info https://github.com/hakimel/reveal.js#dependencies
				dependencies: [
					{ src: '../../../reveal.js/plugin/math/math.js', async: true },
					{ src: '../../../reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: '../../../reveal.js/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: '../../../reveal.js/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: '../../../reveal.js/plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: '../../../reveal.js/plugin/zoom-js/zoom.js', async: true },
					{ src: '../../../reveal.js/plugin/notes/notes.js', async: true }
				]
			});

		</script>

	</body>
</html>
